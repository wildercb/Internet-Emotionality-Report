{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated file saved to titles2017-20230420.csv\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all text files\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def concatenate_csv_files(output_file_path):\n",
    "    # Get a list of all CSV files in the current directory\n",
    "    csv_files = [file for file in os.listdir() if file.endswith('.csv')]\n",
    "\n",
    "    # Load the CSV files into pandas dataframes\n",
    "    dataframes = []\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    concatenated_df = pd.concat(dataframes, axis=0)\n",
    "\n",
    "    # If the output file exists, ask the user whether to overwrite it\n",
    "    if os.path.exists(output_file_path):\n",
    "        user_input = input(f\"The file {output_file_path} already exists. Do you want to overwrite it? (y/n)\")\n",
    "        if user_input.lower() == 'n':\n",
    "            return\n",
    "\n",
    "    # Write the concatenated dataframe to a new CSV file\n",
    "    concatenated_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"Concatenated file saved to {output_file_path}\")\n",
    "\n",
    "\n",
    "concatenate_csv_files('titles2017-20230420.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non alpha numeric characters and extra bits of text grabbed\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_titles(csv_file_path):\n",
    "    # Load the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Clean the 'title' column\n",
    "    df['title'] = df['title'].apply(lambda x: re.sub(r'\\([^()]*\\)', '', str(x))) # remove text enclosed in parentheses\n",
    "    df['title'] = df['title'].apply(lambda x: re.sub(r'[^\\w\\s()]|(?<=\\()\\w+|\\w+(?=\\))', '', str(x)))\n",
    "\n",
    "    # Print the cleaned dataframe\n",
    "    df.to_csv('sentiment_analysis_results.csv',index=False)\n",
    "\n",
    "clean_titles('sentiment_analysis_results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all duplicate titles \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the CSV file\n",
    "df = pd.read_csv('titles2017-20230420Clean.csv')\n",
    "\n",
    "# Drop duplicate rows based on the \"title\" column\n",
    "df.drop_duplicates(subset=\"title\", inplace=True)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv('titles2017-20230420Clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def sort_csv_file_by_date(csv_file_path):\n",
    "    # Load the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Sort the dataframe by the 'date' column\n",
    "    sorted_df = df.sort_values('date', ascending=True)\n",
    "\n",
    "    # Print the sorted dataframe\n",
    "    sorted_df.to_csv('titles2017-20230420Clean.csv', index=False)\n",
    "\n",
    "sort_csv_file_by_date('titles2017-20230420Clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment analysis model\n",
    "specific_model = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "specific_model = pipeline(\"sentiment-analysis\")\n",
    "data = [\"I love you\", \"I hate you\"]\n",
    "specific_model(data)\n",
    "# Read in CSV file\n",
    "df = pd.read_csv(\"titles2017-20230420.csv\")\n",
    "df.dropna(subset=['title'], inplace=True)\n",
    "\n",
    "titles = list(df['title'].astype(str))\n",
    "sentiments = specific_model(titles)\n",
    "\n",
    "# Perform sentiment analysis on each title\n",
    "# sentiments = specific_model(list(df[\"title\"]))\n",
    "\n",
    "# Extract sentiment polarity and subjectivity\n",
    "polarity = [s[\"score\"] for s in sentiments]\n",
    "Plabel = [s[\"label\"] for s in sentiments]\n",
    "\n",
    "# Add new columns to dataframe\n",
    "df[\"TPolarity\"] = polarity\n",
    "df[\"TLabel\"] = Plabel\n",
    "\n",
    "# Write results to new CSV file\n",
    "df.to_csv(\"sentiment_analysis_results.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998656511306763},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991129040718079}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment analysis model\n",
    "specific_model = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "specific_model = pipeline(\"sentiment-analysis\")\n",
    "data = [\"I love you\", \"I hate you\"]\n",
    "specific_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in 1 or 0 for positive or negative \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_titles(csv_file_path):\n",
    "    # Load the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    df['label'] = df['TLabel'].apply(lambda x: 1 if x == 'POSITIVE' else 0)\n",
    "\n",
    "    df.to_csv('SATest.csv',index=False)\n",
    "\n",
    "clean_titles('sentiment_analysis_results - Copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now output files for training transformer so it will be json with text and 0 or 1 for pos/negativity\n",
    "import json\n",
    "\n",
    "def convert_to_json(csv_file_path, json_file_path):\n",
    "    # Load the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Create a list of JSON objects, one for each row in the dataframe\n",
    "    json_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        json_obj = {'label': row['label'], 'text': row['title']}\n",
    "        json_list.append(json_obj)\n",
    "\n",
    "    # Write the list of JSON objects to a text file\n",
    "    with open(json_file_path, 'w') as f:\n",
    "        for json_obj in json_list:\n",
    "            json.dump(json_obj, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "convert_to_json('SATest.csv', 'titles_training.jsonl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively create new file with only the title and lable rows\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def extract_columns(csv_file_path, new_csv_file_path):\n",
    "    # Load the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Extract the 'title' and 'TLabel' columns\n",
    "    df = df[['title', 'label']]\n",
    "\n",
    "    # Output the new CSV file with only the selected columns\n",
    "    df.to_csv(new_csv_file_path, index=False)\n",
    "\n",
    "extract_columns('SATest.csv', 'SATestSimple.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar process above but produces training set with polarity values\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_csv(input_file_path, output_file_path):\n",
    "    # Read in the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    # Negate the 'TPolarity' value if 'TLabel' is 'NEGATIVE'\n",
    "\n",
    "    df.loc[df['TLabel'] == 'NEGATIVE', 'TPolarity'] = -1 * df.loc[df['TLabel'] == 'NEGATIVE', 'TPolarity']\n",
    "    # Select only the 'title' and 'TPolarity' columns\n",
    "\n",
    "\n",
    "    df = df[['title', 'TPolarity']]\n",
    "    # Save the resulting dataframe to a new CSV file\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Example usage:\n",
    "preprocess_csv('SATest.csv', 'SATTestSimple1.0.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
